"""
爬虫课程概要
1. 知识点碎片化
2. 入门简单, 但是后期难
3. 爬虫是灰色地带的产品, 因此触及法律


1. 爬虫的概念:
    网络爬虫, 就是模拟客户端发送网络请求, 接收请求响应
    一种按照一定规则, 自动地抓取互联网信息的程序
    - 原则上, 只要是客户端(浏览器)能做的事情, 爬虫都可以做
    - 爬虫也只能获取客户端(浏览器)所展示出来的数据
    那么重点来了: 如何将爬虫模拟的像浏览器, 这是我们的重点

2. 爬虫的作用
    - 数据采集
    - 软件测试
    - 12306抢票
    - 网站投票, 相当于做一次请求
    - 网络安全
3. 爬虫的分类
    根据被爬取网站的数量不同, 可以分为
        - 通用爬虫: 搜索引擎 # 一直爬取, 依靠链接, 漫无目的的爬取
        - 聚焦爬虫: 例如: 12306, 或者专门抓取某一个(类)网站数据
    根据是否以获取数据为目的
        - 功能性爬虫, 给你喜欢的明星投票, 点赞
        - 数据增量爬虫, 比如招聘信息
    根据url地址和页面内容是否改变, 数据增量爬虫可以分为
        - 基于url地址变化, 内容也随之变化
        - url地址不变, 但是内容变化的数据增量爬虫

4. 爬虫的流程:
    url_list -> 拿出一个url -> 发送请求 -> 解析响应 -> 可以提取数据, 也可以提取其他url补充到url_list
    这与你的提取方式有关, 我们要源源不断的提取url连接, 然后继续爬取数据, 补充给到我们的数据库或者文件中

    流程:
        获取一个url
        向url发送请求, 并且获取响应(需要http协议)
        如果从响应中提取url, 则继续发送请求获取响应
        如果从响应中提取到了我们所需的数据, 我们则需要将数据进行保存, 以便后续进行处理

5. http协议复习:
    https比http更安全, 但是性能更低
    http: 超文本传输协议, 默认端口号是80
    https: http + ssl即带有安全套接字层的超文本传输协议, 默认端口好是443

6. 爬虫特别关注的请求头和响应头
    (1). url格式:
    请求方法 URL 协议版本 回车符换行符    -> 请求行
    头部字段名...值 回车符换行符
    ...                                 -> 请求头部
    [                              }    -> 请求数据

    (2). 爬虫特别关注的请求头和响应头
    爬虫特别关注的几个请求头字段:
        请求头:
        host:                   域名
        connection:             长连接
        upgrade-insecure-Requests: 升级为HTTPS请求
      * user-Agent              用户代理: 告诉服务器客户端,以及所使用的机器的信息
      * Referer                 页面跳转处: 从哪一个页面过来的: 用于检查请求是否合法
                                防盗链: 图片/视频
      * cookie                  cookie: 保持会话, 保持状态. 有时效性
                                常用于判断用户

        这三个是比较重要的.

        响应头:
        Set-Cookie:             对方服务器设置cookie到用户浏览器的缓存


        在爬虫这部分我们要格外关注请求头和响应头, 因为我们需要做伪装
        那么伪装, 就必须用到请求头和响应头


常见的响应状态码:
    - 200: 成功
    - 302: 跳转, 新的url在响应的Location头中给出
    - 303: 浏览器对于POST的响应进行重定向至新的url
    - 307: 浏览器对于GET的响应重定向至新的url
    - 403: 资源不可用; 服务器理解客户的请求, 但是拒绝处理它(没有权限)
    - 404: 找不到该页面
    - 500: 服务器内部错误
    - 503: 服务器由于维护或者负载过重未能应答.

    当然, 状态码也是可以模拟的, 这些都是反爬措施.
    当你收到一个异常的状态码, 那么你可以尝试使用浏览器访问一下试试.

    ** 所有的状态码都不可信, 一切以是否从抓包得到的响应中获取的数据为准!!! **
    请求的Response中看是否有响应数据,才是我们判断是否请求成功的唯一标准
    network中抓包得到的源码才是判断依据, elements中的源码是渲染之后的源码,不能作为判断标准
    elements中是(客户端)渲染后的结果, 是将network中的包中的源码汇总成一个.

浏览器的运行过程:
    首先我们在地址栏中输入url, 然后浏览器会拿着这个url到DNS服务器去查找相应的ip地址返回给浏览器
    然后浏览器再拿着这个ip地址请求服务器, 然后服务器返回页面.
    http请求的过程:
    1. 浏览器在拿到域名对应的ip后, 线向地址栏中的url发起请求, 并获取响应
    2. 在返回的响应内容html中,会带有css,js,图片等url地址, 以及ajax代码, 浏览器按照响应
    内容中的顺序一次发送其他请求, 并获取相应的响应
    3. 浏览器未获取一个响应就对展示处的结果进行加载, js,css等内容会修改页面的内容,
    js也可以重新发送请求, 获取响应
    4. 从获取第一个响应并在浏览器中展示, 直到最终获取全部响应,并在展示的结果中添加内容或求改
    --这个过程叫做浏览器的渲染.

    需要注意的是, 爬虫和浏览器是很不一样的.

    爬虫的过程中:
    但是在爬虫中, 爬虫只会请求url地址, 然后拿到对应url地址对应的响应, 爬虫不具备渲染能力
    爬虫只会请求一个url地址, 而浏览器会自动加载请求中的url,然后展开渲染
    后面我们也有相应的模块, 使得爬虫具有渲染能力, 但是有代价, 性能将会大大折扣

    所以爬虫最重要的, 需要找到真正有数据的请求 -> 抓包

    数据在哪呢?
    前端页面组成:
        骨骼文件: html静态文件
        既然文件: js/ajax文件, 产生动作, 响应
        皮肤:    css/font/图片等文件
    数据可以在这三种文件中的任意一种.
    那么我们从上到下一层一层找

    抓包国臣:
        根据发送请求的流程,分别在 骨骼/肌肉/皮肤 响应找查找数据
        注意顺序.

        在network中, 看包中给的Response, 看是否有我们所需要的数据.
        找到之后, 我们只需要模拟这个请求就可以了, 在请求头中的信息,模拟信息
        至于如何发送请求, 后面会将

        综上, 浏览器展示的结果可以由多次请求的多次  响应共同渲染出来
        而爬虫只能是一次url请求






"""